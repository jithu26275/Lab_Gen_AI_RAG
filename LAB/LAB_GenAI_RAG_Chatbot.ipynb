{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsnCPbdkxYZd"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <h1 style=\"color: #FF6347;\">Self-Guided Lab: Retrieval-Augmented Generation (RAGs)</h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZp4BQAVxYZj"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZ3FsdzRveTBrenMxM3VnbDMwaTJxN2NnZm50aGFibXk1NzNnY2Q0MCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/LR5ZBwZHv02lmpVoEU/giphy.gif\" alt=\"NLP Gif\" style=\"width: 300px; height: 150px; object-fit: cover; object-position: center;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gizk6HCYxYZo"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Data Storage & Retrieval</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW5UOI8ZxYZp"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">PyPDFLoader</h2>\n",
        "\n",
        "`PyPDFLoader` is a lightweight Python library designed to streamline the process of loading and parsing PDF documents for text processing tasks. It is particularly useful in Retrieval-Augmented Generation workflows where text extraction from PDFs is required.\n",
        "\n",
        "- **What Does PyPDFLoader Do?**\n",
        "  - Extracts text from PDF files, retaining formatting and layout.\n",
        "  - Simplifies the preprocessing of document-based datasets.\n",
        "  - Supports efficient and scalable loading of large PDF collections.\n",
        "\n",
        "- **Key Features:**\n",
        "  - Compatible with popular NLP libraries and frameworks.\n",
        "  - Handles multi-page PDFs and embedded images (e.g., OCR-compatible setups).\n",
        "  - Provides flexible configurations for structured text extraction.\n",
        "\n",
        "- **Use Cases:**\n",
        "  - Preparing PDF documents for retrieval-based systems in RAGs.\n",
        "  - Automating the text extraction pipeline for document analysis.\n",
        "  - Creating datasets from academic papers, technical manuals, and reports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (0.3.29)\n",
            "Requirement already satisfied: pypdf in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (6.0.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain) (0.4.25)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain_community) (2.3.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: termcolor in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (3.1.0)\n",
            "Collecting langchain_openai\n",
            "  Obtaining dependency information for langchain_openai from https://files.pythonhosted.org/packages/e6/3d/e22ee65fff79afe7bdfbd67844243eb279b440c882dad9e4262dcc87131f/langchain_openai-0.3.32-py3-none-any.whl.metadata\n",
            "  Using cached langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Obtaining dependency information for langchain-huggingface from https://files.pythonhosted.org/packages/bf/26/7c5d4b4d3e1a7385863acc49fb6f96c55ccf941a750991d18e3f6a69a14a/langchain_huggingface-0.3.1-py3-none-any.whl.metadata\n",
            "  Using cached langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "Collecting sentence-transformers\n",
            "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/6d/70/2b5b76e98191ec3b8b0d1dde52d00ddcc3806799149a9ce987b0d2d31015/sentence_transformers-5.1.0-py3-none-any.whl.metadata\n",
            "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting chromadb\n",
            "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/6f/81/6decbd21c67572d67707f7e168851f10404e2857897456c6ba220e9b09be/chromadb-1.0.20-cp39-abi3-win_amd64.whl.metadata\n",
            "  Using cached chromadb-1.0.20-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
            "Collecting langchain_chroma\n",
            "  Obtaining dependency information for langchain_chroma from https://files.pythonhosted.org/packages/3d/f9/705820c4792540383d4cf9c96fc55784fbd972897f5e84e3160001aba51d/langchain_chroma-0.2.5-py3-none-any.whl.metadata\n",
            "  Using cached langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting tiktoken\n",
            "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/f5/6e/5b71578799b72e5bdcef206a214c3ce860d999d579a3b56e74a6c8989ee2/tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting openai\n",
            "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/00/e1/47887212baa7bc0532880d33d5eafbdb46fcc4b53789b903282a74a85b5b/openai-1.106.1-py3-none-any.whl.metadata\n",
            "  Using cached openai-1.106.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain_openai) (0.3.75)\n",
            "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
            "  Obtaining dependency information for tokenizers>=0.19.1 from https://files.pythonhosted.org/packages/d1/9b/0e0bf82214ee20231845b127aa4a8015936ad5a46779f30865d10e404167/tokenizers-0.22.0-cp39-abi3-win_amd64.whl.metadata\n",
            "  Using cached tokenizers-0.22.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting huggingface-hub>=0.33.4 (from langchain-huggingface)\n",
            "  Obtaining dependency information for huggingface-hub>=0.33.4 from https://files.pythonhosted.org/packages/39/7b/bb06b061991107cd8783f300adff3e7b7f284e330fd82f507f2a1417b11d/huggingface_hub-0.34.4-py3-none-any.whl.metadata\n",
            "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Obtaining dependency information for transformers<5.0.0,>=4.41.0 from https://files.pythonhosted.org/packages/71/7c/283c3dd35e00e22a7803a0b2a65251347b745474a82399be058bde1c9f15/transformers-4.56.1-py3-none-any.whl.metadata\n",
            "  Using cached transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Obtaining dependency information for torch>=1.11.0 from https://files.pythonhosted.org/packages/af/8a/5c87f08e3abd825c7dfecef5a0f1d9aa5df5dd0e3fd1fa2f490a8e512402/torch-2.8.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/15/fa/c61a787e35f05f17fc10523f567677ec4eeee5f95aa4798dbbbcd9625617/scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting scipy (from sentence-transformers)\n",
            "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/14/c3/61f273ae550fbf1667675701112e380881905e28448c080b23b5a181df7c/scipy-1.16.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached scipy-1.16.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Collecting Pillow (from sentence-transformers)\n",
            "  Obtaining dependency information for Pillow from https://files.pythonhosted.org/packages/8c/ce/e7dfc873bdd9828f3b6e5c2bbb74e47a98ec23cc5c74fc4e54462f0d9204/pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Obtaining dependency information for build>=1.0.3 from https://files.pythonhosted.org/packages/cb/8c/2b30c12155ad8de0cf641d76a8b396a16d2c36bc6d50b621a62b7c4567c1/build-1.3.0-py3-none-any.whl.metadata\n",
            "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Obtaining dependency information for pybase64>=1.4.1 from https://files.pythonhosted.org/packages/4f/bc/d5c277496063a09707486180f17abbdbdebbf2f5c4441b20b11d3cb7dc7c/pybase64-1.4.2-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached pybase64-1.4.2-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
            "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Obtaining dependency information for uvicorn[standard]>=0.18.3 from https://files.pythonhosted.org/packages/d2/e2/dc81b1bd1dcfe91735810265e9d26bc8ec5da45b4c0f6237e286819194c3/uvicorn-0.35.0-py3-none-any.whl.metadata\n",
            "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from chromadb) (2.3.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Obtaining dependency information for posthog<6.0.0,>=2.4.0 from https://files.pythonhosted.org/packages/4f/98/e480cab9a08d1c09b1c59a93dade92c1bb7544826684ff2acbfd10fcfbd4/posthog-5.4.0-py3-none-any.whl.metadata\n",
            "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/5d/54/7139d463bb0a312890c9a5db87d7815d4a8cce9e6f5f28d04f0b55fcb160/onnxruntime-1.22.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached onnxruntime-1.22.1-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/bb/ee/6b08dde0a022c463b88f55ae81149584b125a42183407dc1045c486cc870/opentelemetry_api-1.36.0-py3-none-any.whl.metadata\n",
            "  Using cached opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc>=1.2.0 from https://files.pythonhosted.org/packages/0c/67/5f6bd188d66d0fd8e81e681bbf5822e53eb150034e2611dd2b935d3ab61a/opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Obtaining dependency information for opentelemetry-sdk>=1.2.0 from https://files.pythonhosted.org/packages/0b/59/7bed362ad1137ba5886dac8439e84cd2df6d087be7c09574ece47ae9b22c/opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata\n",
            "  Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from chromadb) (0.48.9)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Obtaining dependency information for overrides>=7.3.1 from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/a4/ed/1f1afb2e9e7f38a545d628f864d562a5ae64fe6f7a10e28ffb9b185b4e89/importlib_resources-6.5.2-py3-none-any.whl.metadata\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/84/59/900aa2445891fc47a33f7d2f76e00ca5d6ae6584b20d19af9c06fa09bf9a/grpcio-1.74.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached grpcio-1.74.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Obtaining dependency information for bcrypt>=4.0.1 from https://files.pythonhosted.org/packages/a9/cf/45fb5261ece3e6b9817d3d82b2f343a505fd58674a92577923bc500bd1aa/bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata\n",
            "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Obtaining dependency information for typer>=0.9.0 from https://files.pythonhosted.org/packages/ca/e8/b3d537470e8404659a6335e7af868e90657efb73916ef31ddf3d8b9cb237/typer-0.17.3-py3-none-any.whl.metadata\n",
            "  Using cached typer-0.17.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/89/43/d9bebfc3db7dea6ec80df5cb2aad8d274dd18ec2edd6c4f21f32c237cbbb/kubernetes-33.1.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Obtaining dependency information for mmh3>=4.0.1 from https://files.pythonhosted.org/packages/b8/f6/f6abdcfefcedab3c964868048cfe472764ed358c2bf6819a70dd4ed4ed3a/mmh3-5.2.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached mmh3-5.2.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from chromadb) (0.28.1)\n",
            "Collecting rich>=10.11.0 (from chromadb)\n",
            "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/e3/30/3c4d035596d3cf444529e0b2953ad0466f6049528a879d27534700580395/rich-14.1.0-py3-none-any.whl.metadata\n",
            "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting jsonschema>=4.19.0 (from chromadb)\n",
            "  Obtaining dependency information for jsonschema>=4.19.0 from https://files.pythonhosted.org/packages/bf/9c/8c95d856233c1f82500c2450b8c68576b4cf1c871db3afac5c34ff84e6fd/jsonschema-4.25.1-py3-none-any.whl.metadata\n",
            "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken)\n",
            "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/92/28/6ba31cce05b0f1ec6b787921903f83bd0acf8efde55219435572af83c350/regex-2025.9.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached regex-2025.9.1-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from tiktoken) (2.32.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from openai) (4.10.0)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/9b/52/7ec47455e26f2d6e5f2ea4951a0652c06e5b995c291f723973ae9e724a65/jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: sniffio in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Obtaining dependency information for pyproject_hooks from https://files.pythonhosted.org/packages/bd/24/12818598c362d7f300f18e74db45963dbcb85150324092410c8b49405e42/pyproject_hooks-1.2.0-py3-none-any.whl.metadata\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Requirement already satisfied: certifi in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Collecting filelock (from huggingface-hub>=0.33.4->langchain-huggingface)\n",
            "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/42/14/42b2651a2f46b022ccd948bca9f2d5af0fd8929c4eec235b8d6d844fbe67/filelock-3.19.1-py3-none-any.whl.metadata\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.33.4->langchain-huggingface)\n",
            "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/47/71/70db47e4f6ce3e5c37a607355f80da8860a33226be640226ac52cb05ef2e/fsspec-2025.9.0-py3-none-any.whl.metadata\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
            "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/01/0e/b27cdbaccf30b890c40ed1da9fd4a3593a5cf94dae54fb34f8a4b74fcd3f/jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata\n",
            "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
            "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl.metadata\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
            "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/67/b6/c82f0faa9af1c6a64669f73a17ee0eeef25aff30bb9a1c318509efe45d84/rpds_py-0.27.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached rpds_py-0.27.1-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for google-auth>=1.0.1 from https://files.pythonhosted.org/packages/17/63/b19553b658a1692443c62bd07e5868adaa0ad746a0751ba62c59568cd45b/google_auth-2.40.3-py2.py3-none-any.whl.metadata\n",
            "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for requests-oauthlib from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for oauthlib>=3.2.2 from https://files.pythonhosted.org/packages/be/9c/92789c596b8df838baa98fa71844d84283302f7604ed565dafe5a6b5041a/oauthlib-3.3.1-py3-none-any.whl.metadata\n",
            "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.25)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.33)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/e1/59/0a820b7310f8139bd8d5a9388e6a38e1786d179d6f33998448609296c229/protobuf-6.32.0-cp310-abi3-win_amd64.whl.metadata\n",
            "  Using cached protobuf-6.32.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: sympy in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for importlib-metadata<8.8.0,>=6.0 from https://files.pythonhosted.org/packages/20/b0/36bd937216ec521246249be3bf9855081de4c5e06a0c9b4219dbeda50373/importlib_metadata-8.7.0-py3-none-any.whl.metadata\n",
            "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for googleapis-common-protos~=1.57 from https://files.pythonhosted.org/packages/86/f1/62a193f0227cf15a920390abe675f386dec35f7ae3ffe6da582d3ade42c7/googleapis_common_protos-1.70.0-py3-none-any.whl.metadata\n",
            "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.36.0 from https://files.pythonhosted.org/packages/d0/ed/22290dca7db78eb32e0101738366b5bbda00d0407f00feffb9bf8c3fdf87/opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-proto==1.36.0 from https://files.pythonhosted.org/packages/b3/57/3361e06136225be8180e879199caea520f38026f8071366241ac458beb8d/opentelemetry_proto-1.36.0-py3-none-any.whl.metadata\n",
            "  Using cached opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-semantic-conventions==0.57b0 from https://files.pythonhosted.org/packages/05/75/7d591371c6c39c73de5ce5da5a2cc7b72d1d1cd3f8f4638f553c01c37b11/opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata\n",
            "  Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Obtaining dependency information for backoff>=1.10.0 from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
            "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/94/54/e7d793b573f298e1c9013b8c4dade17d481164aa517d1d7148619c2cedbf/markdown_it_py-4.0.0-py3-none-any.whl.metadata\n",
            "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
            "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/eb/8d/776adee7bbf76365fdd7f2552710282c79a4ead5d2a46408c9043a2b70ba/networkx-3.5-py3-none-any.whl.metadata\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl.metadata\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
            "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/2c/c3/c0be1135726618dc1e28d181b8c442403d8dbb9e273fd791de2d4384bcdd/safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata\n",
            "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
            "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
            "  Obtaining dependency information for click>=8.0.0 from https://files.pythonhosted.org/packages/85/32/10bb5764d90a8eee674e9dc6f4db6a0ab47c8c4d0d83c27f7c39ac415a4d/click-8.2.1-py3-none-any.whl.metadata\n",
            "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Obtaining dependency information for httptools>=0.6.3 from https://files.pythonhosted.org/packages/12/b7/5cae71a8868e555f3f67a50ee7f673ce36eac970f029c0c5e9d584352961/httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/3f/d3/3ae9d5124ec75143bdf088d436cba39812122edc47709cd2caafeac3266f/watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
            "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/1e/e8/685f47e0d754320684db4425a0967f7d3fa70126bffd76110b7009a0090f/joblib-1.5.2-py3-none-any.whl.metadata\n",
            "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/72/76/20fa66124dbe6be5cafeb312ece67de6b61dd91a0247d1ea13db4ebb33c2/cachetools-5.5.2-py3-none-any.whl.metadata\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for pyasn1-modules>=0.2.1 from https://files.pythonhosted.org/packages/47/8d/d529b5d697919ba8c11ad626e835d4039be708a35b0d22de83a269a6682c/pyasn1_modules-0.4.2-py3-none-any.whl.metadata\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl.metadata\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.24.0)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
            "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jithin\\onedrive\\desktop\\bootcamp\\bootcamp_labs\\week_7\\d5\\lab\\gen_ai\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
            "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/c1/80/a61f99dc3a936413c3ee4e1eecac96c0da5ed07ad56fd975f1a9da5bc630/MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Obtaining dependency information for pyreadline3 from https://files.pythonhosted.org/packages/5a/dc/491b7661614ab97483abf2056be1deee4dc2490ecbf7bff9ab5cdbac86e1/pyreadline3-3.5.4-py3-none-any.whl.metadata\n",
            "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for pyasn1<0.7.0,>=0.6.1 from https://files.pythonhosted.org/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl.metadata\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Using cached langchain_openai-0.3.32-py3-none-any.whl (74 kB)\n",
            "Using cached langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
            "Using cached chromadb-1.0.20-cp39-abi3-win_amd64.whl (19.8 MB)\n",
            "Using cached langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
            "Using cached tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
            "Using cached openai-1.106.1-py3-none-any.whl (930 kB)\n",
            "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
            "Using cached build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached grpcio-1.74.0-cp312-cp312-win_amd64.whl (4.5 MB)\n",
            "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
            "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "Using cached mmh3-5.2.0-cp312-cp312-win_amd64.whl (41 kB)\n",
            "Using cached onnxruntime-1.22.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
            "Using cached opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "Using cached pybase64-1.4.2-cp312-cp312-win_amd64.whl (35 kB)\n",
            "Using cached regex-2025.9.1-cp312-cp312-win_amd64.whl (275 kB)\n",
            "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
            "Using cached tokenizers-0.22.0-cp39-abi3-win_amd64.whl (2.7 MB)\n",
            "Using cached torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
            "Using cached transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
            "Using cached typer-0.17.3-py3-none-any.whl (46 kB)\n",
            "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
            "Using cached scikit_learn-1.7.1-cp312-cp312-win_amd64.whl (8.7 MB)\n",
            "Using cached scipy-1.16.1-cp312-cp312-win_amd64.whl (38.5 MB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
            "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "Using cached protobuf-6.32.0-cp310-abi3-win_amd64.whl (435 kB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached rpds_py-0.27.1-cp312-cp312-win_amd64.whl (232 kB)\n",
            "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
            "Using cached watchfiles-1.1.0-cp312-cp312-win_amd64.whl (292 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: scipy, safetensors, rpds-py, regex, pyreadline3, pyproject_hooks, pybase64, pyasn1, protobuf, Pillow, overrides, oauthlib, networkx, mmh3, mdurl, MarkupSafe, joblib, jiter, importlib-resources, importlib-metadata, httptools, grpcio, fsspec, filelock, distro, click, cachetools, bcrypt, backoff, watchfiles, uvicorn, tiktoken, scikit-learn, rsa, requests-oauthlib, referencing, pyasn1-modules, posthog, opentelemetry-proto, opentelemetry-api, markdown-it-py, jinja2, humanfriendly, huggingface-hub, googleapis-common-protos, build, torch, tokenizers, rich, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, openai, jsonschema-specifications, google-auth, coloredlogs, typer, transformers, opentelemetry-sdk, onnxruntime, kubernetes, jsonschema, sentence-transformers, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, langchain-huggingface, chromadb, langchain_chroma\n",
            "Successfully installed MarkupSafe-3.0.2 Pillow-11.3.0 backoff-2.2.1 bcrypt-4.3.0 build-1.3.0 cachetools-5.5.2 chromadb-1.0.20 click-8.2.1 coloredlogs-15.0.1 distro-1.9.0 filelock-3.19.1 fsspec-2025.9.0 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.74.0 httptools-0.6.4 huggingface-hub-0.34.4 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jinja2-3.1.6 jiter-0.10.0 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 langchain-huggingface-0.3.1 langchain_chroma-0.2.5 langchain_openai-0.3.32 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 networkx-3.5 oauthlib-3.3.1 onnxruntime-1.22.1 openai-1.106.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 protobuf-6.32.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pyproject_hooks-1.2.0 pyreadline3-3.5.4 referencing-0.36.2 regex-2025.9.1 requests-oauthlib-2.0.0 rich-14.1.0 rpds-py-0.27.1 rsa-4.9.1 safetensors-0.6.2 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-5.1.0 tiktoken-0.11.0 tokenizers-0.22.0 torch-2.8.0 transformers-4.56.1 typer-0.17.3 uvicorn-0.35.0 watchfiles-1.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain langchain_community pypdf\n",
        "%pip install termcolor langchain_openai langchain-huggingface sentence-transformers chromadb langchain_chroma tiktoken openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6heKZkQUxYZr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRS44B2XxYZs",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Loading the Documents</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cuREtJRixYZt"
      },
      "outputs": [],
      "source": [
        "# File path for the document\n",
        "\n",
        "file_path = \"../LAB/ai-for-everyone.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz_8SOLxxYZt"
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Documents into pages</h3>\n",
        "\n",
        "The `PyPDFLoader` library allows efficient loading and splitting of PDF documents into smaller, manageable parts for NLP tasks.\n",
        "\n",
        "This functionality is particularly useful in workflows requiring granular text processing, such as Retrieval-Augmented Generation (RAG).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_b5Z_45UxYZu",
        "outputId": "a600d69f-14fe-4492-f236-97261d6ff36c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "297"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and split the document\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = loader.load_and_split()\n",
        "len(pages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt50NRQaxYZv"
      },
      "source": [
        "<h3 style=\"color: #FF8C00;\">Pages into Chunks</h3>\n",
        "\n",
        "\n",
        "####  RecursiveCharacterTextSplitter in LangChain\n",
        "\n",
        "The `RecursiveCharacterTextSplitter` is the **recommended splitter** in LangChain when you want to break down long documents into smaller, semantically meaningful chunks — especially useful in **RAG pipelines**, where clean context chunks lead to better LLM responses.\n",
        "\n",
        "####  Parameters\n",
        "\n",
        "| Parameter       | Description                                                                 |\n",
        "|-----------------|-----------------------------------------------------------------------------|\n",
        "| `chunk_size`    | The **maximum number of characters** allowed in a chunk (e.g., `1000`).     |\n",
        "| `chunk_overlap` | The number of **overlapping characters** between consecutive chunks (e.g., `200`). This helps preserve context continuity. |\n",
        "\n",
        "####  How it works\n",
        "`RecursiveCharacterTextSplitter` attempts to split the text **intelligently**, trying the following separators in order:\n",
        "1. Paragraphs (`\"\\n\\n\"`)\n",
        "2. Lines (`\"\\n\"`)\n",
        "3. Sentences or words (`\" \"`)\n",
        "4. Individual characters (as a last resort)\n",
        "\n",
        "This makes it ideal for handling **natural language documents**, such as PDFs, articles, or long reports, without breaking sentences or paragraphs in awkward ways.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1096"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  Alternative: CharacterTextSplitter\n",
        "\n",
        "`CharacterTextSplitter` is a simpler splitter that breaks text into chunks based **purely on character count**, without trying to preserve any natural language structure.\n",
        "\n",
        "##### Example:\n",
        "```python\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "````\n",
        "\n",
        "This method is faster and more predictable but may split text in the middle of a sentence or paragraph, which can hurt performance in downstream tasks like retrieval or QA.\n",
        "\n",
        "---\n",
        "\n",
        "#### Comparison Table\n",
        "\n",
        "| Feature                        | RecursiveCharacterTextSplitter | CharacterTextSplitter     |\n",
        "| ------------------------------ | ------------------------------ | ------------------------- |\n",
        "| Structure-aware splitting      |  Yes                          |  No                      |\n",
        "| Preserves sentence/paragraphs  |  Yes                          |  No                      |\n",
        "| Risk of splitting mid-sentence |  Minimal                     |  High                   |\n",
        "| Ideal for RAG/document QA      |  Highly recommended           |  Only if structured text |\n",
        "| Performance speed              |  Slightly slower             |  Faster                  |\n",
        "\n",
        "---\n",
        "\n",
        "#### Recommendation\n",
        "\n",
        "Use `RecursiveCharacterTextSplitter` for most real-world document processing tasks, especially when building RAG pipelines or working with structured natural language content like PDFs or articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices for Choosing Chunk Size in RAG\n",
        "\n",
        "### Best Practices for Chunk Size in RAG\n",
        "\n",
        "| Factor                      | Recommendation                                                                                                                                                                                          |\n",
        "| ---------------------------| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **LLM context limit**       | Choose a chunk size that lets you retrieve multiple chunks **without exceeding the model’s token limit**. For example, GPT-4o supports 128k tokens, but with GPT-3.5 (16k) or GPT-4 (32k), keep it modest. |\n",
        "| **Chunk size (in characters)** | Typically: **500–1,000 characters** per chunk → ~75–200 tokens. This fits well for retrieval + prompt without context overflow.                                                                           |\n",
        "| **Chunk size (in tokens)**  | If using token-based splitter (e.g. `TokenTextSplitter`): aim for **100–300 tokens** per chunk.                                                                                                            |\n",
        "| **Chunk overlap**           | Use **overlap of 10–30%** (e.g., 100–300 characters or ~50 tokens) to preserve context across chunk boundaries and avoid cutting off important ideas mid-sentence.                                        |\n",
        "| **Document structure**      | Use **`RecursiveCharacterTextSplitter`** to preserve semantic boundaries (paragraphs, sentences) instead of arbitrary cuts.                                                                                |\n",
        "| **Task type**               | For **question answering**, smaller chunks (~500–800 chars) reduce noise.<br>For **summarization**, slightly larger chunks (~1000–1500) are OK.                                                          |\n",
        "| **Embedding model**         | Some models (e.g., `text-embedding-3-large`) can handle long input. But still, smaller chunks give **finer-grained retrieval**, which improves relevance.                                                  |\n",
        "| **Query type**              | If users ask **very specific questions**, small focused chunks are better. For broader queries, bigger chunks might help.                                                                                  |\n",
        "\n",
        "\n",
        "### Rule of Thumb\n",
        "\n",
        "| Use Case                 | Chunk Size      | Overlap |\n",
        "| ------------------------| --------------- | ------- |\n",
        "| Factual Q&A              | 500–800 chars   | 100–200 |\n",
        "| Summarization            | 1000–1500 chars | 200–300 |\n",
        "| Technical documents      | 400–700 chars   | 100–200 |\n",
        "| Long reports/books       | 800–1200 chars  | 200–300 |\n",
        "| Small LLMs (≤16k tokens) | ≤800 chars      | 100–200 |\n",
        "\n",
        "\n",
        "### Avoid\n",
        "\n",
        "- Chunks >2000 characters: risks context overflow.\n",
        "- No overlap: may lose key information between chunks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg15RjVPxYZw"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">Embeddings</h2>\n",
        "\n",
        "Embeddings transform text into dense vector representations, capturing semantic meaning and contextual relationships. They are essential for efficient document retrieval and similarity analysis.\n",
        "\n",
        "- **What are OpenAI Embeddings?**\n",
        "  - Pre-trained embeddings like `text-embedding-3-large` generate high-quality vector representations for text.\n",
        "  - Encapsulate semantic relationships in the text, enabling robust NLP applications.\n",
        "\n",
        "- **Key Features of `text-embedding-3-large`:**\n",
        "  - Large-scale embedding model optimized for accuracy and versatility.\n",
        "  - Handles diverse NLP tasks, including retrieval, classification, and clustering.\n",
        "  - Ideal for applications with high-performance requirements.\n",
        "\n",
        "- **Benefits:**\n",
        "  - Reduces the need for extensive custom training.\n",
        "  - Provides state-of-the-art performance in retrieval-augmented systems.\n",
        "  - Compatible with RAGs to create powerful context-aware models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L0xDxElwxYZw"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_WRIo3_0xYZx",
        "outputId": "78bfbbf3-9d25-4e31-bdbc-3e932e6bbfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MNZfTng5xYZz",
        "outputId": "db1a7c85-ef9f-447e-92cd-9d097e959847"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsSA7RKvxYZz"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">ChromaDB</h2>\n",
        "\n",
        "ChromaDB is a versatile vector database designed for efficiently storing and retrieving embeddings. It integrates seamlessly with embedding models to enable high-performance similarity search and context-based retrieval.\n",
        "\n",
        "### Workflow Overview:\n",
        "- **Step 1:** Generate embeddings using a pre-trained model (e.g., OpenAI's `text-embedding-3-large`).\n",
        "- **Step 2:** Store the embeddings in ChromaDB for efficient retrieval and similarity calculations.\n",
        "- **Step 3:** Use the stored embeddings to perform searches, matching, or context-based retrieval.\n",
        "\n",
        "### Key Features of ChromaDB:\n",
        "- **Scalability:** Handles large-scale datasets with optimized indexing and search capabilities.\n",
        "- **Speed:** Provides fast and accurate retrieval of embeddings for real-time applications.\n",
        "- **Integration:** Supports integration with popular frameworks and libraries for embedding generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "brKe6wUgxYZ0"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VkjHR-RkxYZ0",
        "outputId": "bc11bda9-f283-457a-f584-5a06b95c4dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChromaDB created with document embeddings.\n"
          ]
        }
      ],
      "source": [
        "db = Chroma.from_documents(chunks, embeddings, persist_directory=\"./chroma_db_LAB\")\n",
        "print(\"ChromaDB created with document embeddings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27OdN1IVxYZ1"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Retrieving Documents</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice1: Write a user question that someone might ask about your book’s topic or content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XiLv-TfrxYZ1"
      },
      "outputs": [],
      "source": [
        "user_question = \"what this book is useful for ?\" # User question\n",
        "retrieved_docs = db.similarity_search(user_question, k=10) # k is the number of documents to retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qgWsh50JxYZ1",
        "outputId": "c8640c5d-5955-471f-fdd2-37096f5f68c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "vestigates the normative projections of what \n",
            "AI should be and what it should do. This section poses critical questions about \n",
            "how AI needs to debunk the myths surrounding it.\n",
            "Part 3: AI Power and Inequalities – advances the debate around AI by criti -\n",
            "cally examining what ‘ AI for Everyone?’ means. This is dealing with the root of \n",
            "the problem: who will benefit from AI is ultimately down to who has the power \n",
            "to decide. These contributions look at how AI capitalism is organised, what \n",
            "(new) inequalities it might bring about and how we can fight back.\n",
            "Why do we need a book on AI for Everyone? and why do we need it now? \n",
            "The 2007–2008 financial crisis, and the resulting global economic crisis, has not \n",
            "only brought about a decade of austerity in large parts of the Western world; \n",
            "it has also been the context in which social media and digital platforms have \n",
            "transformed into behemoths. Tech companies are now dominating the top 10\n",
            "Document 2:\n",
            " accessible for everyone. Further in this intro-\n",
            "duction, I elaborate on this and I make the case for a radical democratisation of \n",
            "AI, and why we need to put power at the centre for achieving this.\n",
            "The contributions in this book braid discussion of power and critique with \n",
            "three strands: AI – Humans vs. Machines, Discourses and Myths About AI and \n",
            "AI Power and Inequalities. \n",
            "Part 1: AI – Humans vs. Machines – deals with the history and conceptualisa-\n",
            "tion of AI and what is at stake in its development. This section looks at different \n",
            "perspectives about what characterises machine intelligence and how it might \n",
            "be important to further radical humanism in the era of automation and AI. \n",
            "Part 2: Discourses and Myths About AI – analyses how AI is framed in popu-\n",
            "lar and scholarly discussions and investigates the normative projections of what \n",
            "AI should be and what it should do. This section poses critical questions about\n",
            "Document 3:\n",
            "VESPIETER VERDEGEM /parenleft.caseED ./parenright.case\n",
            " uwestminsterpress.co.uk\n",
            "AI FOR EVERYONE?\n",
            "W\n",
            "e are entering a new era of technological determinism and \n",
            "solutionism in which governments and business actors are \n",
            "seeking data-driven change, assuming that Artiﬁ  cial Intelligence \n",
            "is now inevitable and ubiquitous. But we have not even started asking the \n",
            "right questions, let alone developed an understanding of the consequences. \n",
            "Urgently needed is debate that asks and answers fundamental questions \n",
            "about power.\n",
            "This book brings together critical interrogations of what constitutes \n",
            "AI, its impact and its inequalities in order to offer an analysis of what it \n",
            "means for AI to deliver beneﬁ  ts for everyone. The book is structured in \n",
            "three parts: Part 1, AI: Humans vs. Machines, presents critical perspectives \n",
            "on human-machine dualism. Part 2, Discourses and Myths about AI, \n",
            "excavates metaphors and policies to ask normative questions about what\n"
          ]
        }
      ],
      "source": [
        "# Display top results\n",
        "for i, doc in enumerate(retrieved_docs[:3]): # Display top 3 results\n",
        "    print(f\"Document {i+1}:\\n{doc.page_content[36:1000]}\") # Display content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuGK8gL6xYZ1"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">Preparing Content for GenAI</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2iB3lZqHxYZ2"
      },
      "outputs": [],
      "source": [
        "def _get_document_prompt(docs):\n",
        "    prompt = \"\\n\"\n",
        "    for doc in docs:\n",
        "        prompt += \"\\nContent:\\n\"\n",
        "        prompt += doc.page_content + \"\\n\\n\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2okzmuADxYZ2",
        "outputId": "0aa6cdca-188d-40e0-f5b4-8888d3549ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context formatted for GPT model.\n"
          ]
        }
      ],
      "source": [
        "# Generate a formatted context from the retrieved documents\n",
        "formatted_context = _get_document_prompt(retrieved_docs)\n",
        "print(\"Context formatted for GPT model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzIczQNTxYZ2"
      },
      "source": [
        "<h2 style=\"color: #FF8C00;\">ChatBot Architecture</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice2: Write a prompt that is relevant and tailored to the content and style of your book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tqxVh9s3xYZ3",
        "outputId": "97cca95d-4ab3-44d8-a76c-5713aad387d8"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a teacher explaining concepts from the book 'AI for Everyone' to a general audience.\n",
        "Summarize the content in simple, beginner-friendly language. \n",
        "Focus on:\n",
        "1. What AI is and what it is not. \n",
        "2. How AI impacts everyday life. \n",
        "3. Examples of how businesses and society use AI. \n",
        "Avoid heavy technical jargon. Use analogies and real-life examples to make it engaging.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0mjkQJ_ZxYZ3"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice3: Tune parameters like temperature, and penalties to control how creative, focused, or varied the model's responses are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ylypRWRlxYZ4"
      },
      "outputs": [],
      "source": [
        "# Set up GPT client and parameters\n",
        "\n",
        "client = openai.OpenAI()\n",
        "\n",
        "model_params = {\n",
        "    'model': 'gpt-4o',      # Optimized GPT-4\n",
        "    'temperature': 0.7,     # 0 = deterministic, 1 = very creative\n",
        "    'max_tokens': 500,      # Limit response length (increase if you want essays)\n",
        "    'top_p': 0.9,           # Nucleus sampling (balance between diversity & focus)\n",
        "    'frequency_penalty': 0.2,  # Small penalty to reduce word/phrase repetition\n",
        "    'presence_penalty': 0.4    # Encourages the model to introduce new ideas/topics\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8e942xDxYZ4"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Response</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4eXZO4pIxYZ4"
      },
      "outputs": [],
      "source": [
        "messages = [{'role': 'user', 'content': prompt}]\n",
        "completion = client.chat.completions.create(messages=messages, **model_params, timeout=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wLPAcchBxYZ5",
        "outputId": "976c7800-16ed-41fe-c4cf-58f60d3230d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Certainly! Let's dive into the fascinating world of Artificial Intelligence (AI) in a way that's easy to understand.\n",
            "\n",
            "### 1. What AI is and what it is not\n",
            "\n",
            "**What AI Is:**\n",
            "Think of AI as a smart helper that can learn from experiences, like how we humans do. It's a type of computer program or machine that can perform tasks which usually require human intelligence. This includes recognizing speech, making decisions, solving problems, and even understanding language.\n",
            "\n",
            "**What AI Is Not:**\n",
            "AI isn't a magical robot or a super-intelligent being from science fiction movies. It's not something with emotions or consciousness. It doesn't \"think\" like humans but rather follows complex sets of instructions designed by people to solve specific problems. \n",
            "\n",
            "Imagine teaching a dog new tricks; you give it commands and reward it when it does well. Similarly, we \"train\" AI using lots of data and examples to make it perform certain tasks effectively.\n",
            "\n",
            "### 2. How AI impacts everyday life\n",
            "\n",
            "AI has quietly become a part of our daily routines without many of us even realizing it. Here are some simple ways it's impacting our lives:\n",
            "\n",
            "- **Smart Assistants:** Devices like Alexa or Siri use AI to understand your voice commands and help you set reminders, play music, or answer questions.\n",
            "- **Personalized Recommendations:** When you watch Netflix or shop online, AI suggests movies or products you might like based on your past preferences.\n",
            "- **Navigation:** Apps like Google Maps use AI to provide real-time traffic updates and suggest the fastest routes for your journey.\n",
            "- **Spam Filters:** Your email service uses AI to detect and filter out spam messages, so you only see the emails that matter.\n",
            "\n",
            "### 3. Examples of how businesses and society use AI\n",
            "\n",
            "AI is like a secret ingredient that makes many things work better across various industries:\n",
            "\n",
            "- **Healthcare:** Doctors use AI to analyze medical images, helping them detect diseases like cancer more accurately and quickly than before.\n",
            "- **Finance:** Banks employ AI to monitor transactions for fraudulent activities, keeping your money safe by flagging suspicious actions.\n",
            "- **Retail:** Stores use AI to manage inventory efficiently, ensuring popular items are always in stock while reducing waste.\n",
            "- **Agriculture:** Farmers benefit from AI by using drones and sensors to monitor crops' health and optimize water usage, leading to better yields with fewer resources.\n",
            "\n",
            "In society, AI helps improve public services too:\n",
            "\n",
            "- **City Planning:** Some cities use AI to manage traffic lights dynamically, reducing congestion and improving travel\n"
          ]
        }
      ],
      "source": [
        "answer = completion.choices[0].message.content\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXVNXPwLxYaT"
      },
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:824/1*GK56xmDIWtNQAD_jnBIt2g.png\" alt=\"NLP Gif\" style=\"width: 500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldybhlqKxYaT"
      },
      "source": [
        "<h2 style=\"color: #FF6347;\">Cosine Similarity</h2>\n",
        "\n",
        "**Cosine similarity** is a metric used to measure the alignment or similarity between two vectors, calculated as the cosine of the angle between them. It is the **most common metric used in RAG pipelines** for vector retrieval.. It provides a scale from -1 to 1:\n",
        "\n",
        "- **-1**: Vectors are completely opposite.\n",
        "- **0**: Vectors are orthogonal (uncorrelated or unrelated).\n",
        "- **1**: Vectors are identical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1I1TNhxYaT"
      },
      "source": [
        "<img src=\"https://storage.googleapis.com/lds-media/images/cosine-similarity-vectors.original.jpg\" alt=\"NLP Gif\" style=\"width: 700px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoEMdNgQxYaU"
      },
      "source": [
        "<h2 style=\"color: #FF6347;\">Keyword Highlighting</h2>\n",
        "\n",
        "Highlighting important keywords helps users quickly understand the relevance of the retrieved text to their query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nCXL9Cz1xYaV"
      },
      "outputs": [],
      "source": [
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwDyofY0xYaV"
      },
      "source": [
        "The `highlight_keywords` function is designed to highlight specific keywords within a given text. It replaces each keyword in the text with a highlighted version using the `colored` function from the `termcolor` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9y3E0YWExYaV"
      },
      "outputs": [],
      "source": [
        "def highlight_keywords(text, keywords):\n",
        "    for keyword in keywords:\n",
        "        text = text.replace(keyword, colored(keyword, 'green', attrs=['bold']))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice4: add your keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "i7SkWPpnxYaW",
        "outputId": "28e82563-edba-4b41-acad-ec27e5ba134f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Snippet 1:\n",
            "lar and scholarly discussions and investigates the normative projections of what \n",
            "\u001b[1m\u001b[32mAI\u001b[0m should be and what it should do. This section poses critical questions about \n",
            "how \u001b[1m\u001b[32mAI\u001b[0m needs to debunk the myths surr\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "query_keywords = [\"AI\", \"machine learning\", \"neural networks\", \"ethics\"]\n",
        "\n",
        "for i, doc in enumerate(retrieved_docs[:1]):   # Just showing the first retrieved doc\n",
        "    snippet = doc.page_content[:200]           # Take the first 200 characters\n",
        "    highlighted = highlight_keywords(snippet, query_keywords)  \n",
        "    print(f\"Snippet {i+1}:\\n{highlighted}\\n{'-'*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhV_Jf_LxYaX"
      },
      "source": [
        "1. `query_keywords` is a list of keywords to be highlighted.\n",
        "2. The loop iterates over the first document in retrieved_docs.\n",
        "3. For each document, a snippet of the first 200 characters is extracted.\n",
        "4. The highlight_keywords function is called to highlight the keywords in the snippet.\n",
        "5. The highlighted snippet is printed along with a separator line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBRKysAvxYaX"
      },
      "source": [
        "<h1 style=\"color: #FF6347;\">Bonus</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj25lCybxYaX"
      },
      "source": [
        "**Try loading one of your own PDF books and go through the steps again to explore how the pipeline works with your content**:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gen_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
